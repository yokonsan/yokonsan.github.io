<!DOCTYPE html>
<html lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="yokonsan" />
	
	
	
	<title>Python爬虫(13):Scrapy实战抓取网易云音乐 ｜ 乾之 三爻</title>
	
    
    
    <meta name="description" content="前两篇文章我们了解了 Scrapy 的理论知识，那么我们不能做纸上谈兵的赵括。实践才是检验真理的唯一标准。本篇文章我们来抓取网易云音乐的所有音乐及音乐的热评。 分析站点 我们打开浏览器，访问网易云音乐的网页端。如果我们" />
    

    
    
    <meta name="keywords" content="技术, 生活, 分享" />
    

	
    
    <link rel="shortcut icon" href="https://yokonsan.com/images/favicon.ico" />

    <link rel="stylesheet" type="text/css" media="screen" href="https://yokonsan.com/css/normalize.css" />
    <link rel="stylesheet" type="text/css" media="screen" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" />
    <link rel="stylesheet" type="text/css" media="screen" href="https://yokonsan.com/css/zozo.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" />
    <link rel="stylesheet" type="text/css" media="screen" href="https://yokonsan.com/css/highlight.css" />

    
    
</head>

<body>
    <div class="main animate__animated animate__fadeInDown">
        <div class="nav_container animated fadeInDown">
    <div class="site_nav" id="site_nav">
        <ul>
            
            <li>
                <a href="/">Home</a>
            </li>
            
            <li>
                <a href="/posts/">Archive</a>
            </li>
            
            <li>
                <a href="/tags/">Tags</a>
            </li>
            
            <li>
                <a href="/about/">About</a>
            </li>
            
            <li>
                <a href="/links/">Links</a>
            </li>
            
        </ul>
    </div>
    <div class="menu_icon">
        <a id="menu_icon"><i class="ri-menu-line"></i></a>
    </div>
</div>
        <div class="header animated fadeInDown">
    <div class="site_title_container">
        <div class="site_title">
            <h1>
                <a href="https://yokonsan.com/">
                    <span>乾之 三爻</span>
                </a>
            </h1>
        </div>
        <div class="description">
            <p class="sub_title">yokon&#39;s blog</p>
            <div class="my_socials">
                
                
                <a href="https://github.com/yokonsan" title="github" target="_blank"><i class="ri-github-fill"></i></a>
                
                
                
                <a href="https://openai.yokonsan.com" title="instagram" target="_blank"><i class="ri-instagram-fill"></i></a>
                
                
                <a href="https://yokonsan.com/index.xml" type="application/rss+xml" title="rss" target="_blank"><i
                        class="ri-rss-fill"></i></a>
            </div>
        </div>
    </div>
</div>
        <div class="content">
            <div class="post_page">
                <div class="post animate__animated animate__fadeInDown">
                    <div class="post_title post_detail_title">
                        <h2><a href='/posts/2017/7/python-spider-163music/'>Python爬虫(13):Scrapy实战抓取网易云音乐</a></h2>
                        <span class="date">2017.07.29</span>
                    </div>
                    <div class="post_content markdown"><p>前两篇文章我们了解了 Scrapy 的理论知识，那么我们不能做纸上谈兵的赵括。实践才是检验真理的唯一标准。本篇文章我们来抓取网易云音乐的所有音乐及音乐的热评。</p>
<h2 id="分析站点">分析站点</h2>
<p>我们打开浏览器，访问网易云音乐的网页端。如果我们想要抓取到所有的音乐，就得有一个切入口，能够获得到所有的音乐数据。</p>
<p>那么通过观察页面的导航，我们只能通过获取全部的歌手。但是由于歌手详情页并没有全部音乐这个链接，我们只能获取全部的专辑。在通过全部的专辑获得全部的音乐。</p>
<h2 id="爬虫流程">爬虫流程</h2>
<p>以歌手页为索引页，抓取所有的歌手；
通过所有的歌手抓取全部专辑；
通过全部专辑抓取所有的音乐；
分析所有音乐的Ajax，获得所有热评；
将音乐名，歌手，专辑，热评，热评作者，热评赞数保存数据库。</p>
<h2 id="开始">开始</h2>
<h3 id="创建项目">创建项目</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">scrapy startproject 163music
</span></span></code></pre></div><h3 id="创建爬虫文件可以通过命令行创建">创建爬虫文件（可以通过命令行创建）：</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># spiders/spider.py</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scrapy</span> <span class="kn">import</span> <span class="n">Spider</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MusicSpider</span><span class="p">(</span><span class="n">Spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">name</span> <span class="o">=</span> <span class="s2">&#34;music&#34;</span>
</span></span><span class="line"><span class="cl">	<span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;163.com&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;https://music.163.com&#39;</span>
</span></span></code></pre></div><h3 id="确定数据名称">确定数据名称</h3>
<p>我们先将要保存下来得到数据写到 item 文件中，虽然这一步不是必须先写，但是我们按照流程来不会错。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">#items.py</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">scrapy</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MusicItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="c1"># define the fields for your item here like:</span>
</span></span><span class="line"><span class="cl">	<span class="c1"># 我们保存歌曲的id</span>
</span></span><span class="line"><span class="cl">	<span class="nb">id</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="n">artist</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="n">album</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="n">music</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="n">comments</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</span></span></code></pre></div><h3 id="分析索引页">分析索引页</h3>
<p>我们的索引页为歌手页，地址：<code>https://music.163.com/#/discover/artist/cat?id=1001&amp;amp;initial=65</code></p>
<p><img src="/image/post18/post18_1.jpg" alt="post18_1.jpg"></p>
<p>通过图片结合我们对索引页的观察，我们可以看到左侧比如华语男歌手，欧美男歌手是分类，而歌手下的ABCDE也是一个按姓名的分类。</p>
<p>通过观察链接可以发现，<code>id</code>就是左侧分类的值，<code>initial</code>是 ABCDE 链接的值。</p>
<p>我们可以发现 ABCDE 每一个链接是从 65 开始，一直到 90，再加上&rsquo;其他&rsquo;链接为 0。这样的规则我们是可以用代码很简单实现的。而左侧的歌手分类的数字相对是不好用代码实现他的规则的。索性他的数目不多，我们一个一个写出来保存集合就可以了。我们将这两个参数写到爬虫类中。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MusicSpider</span><span class="p">(</span><span class="n">Spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">name</span> <span class="o">=</span> <span class="s2">&#34;music&#34;</span>
</span></span><span class="line"><span class="cl">	<span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;163.com&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;https://music.163.com&#39;</span>
</span></span><span class="line"><span class="cl">	<span class="n">ids</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;1001&#39;</span><span class="p">,</span><span class="s1">&#39;1002&#39;</span><span class="p">,</span><span class="s1">&#39;1003&#39;</span><span class="p">,</span><span class="s1">&#39;2001&#39;</span><span class="p">,</span><span class="s1">&#39;2002&#39;</span><span class="p">,</span><span class="s1">&#39;2003&#39;</span><span class="p">,</span><span class="s1">&#39;6001&#39;</span><span class="p">,</span><span class="s1">&#39;6002&#39;</span><span class="p">,</span><span class="s1">&#39;6003&#39;</span><span class="p">,</span><span class="s1">&#39;7001&#39;</span><span class="p">,</span><span class="s1">&#39;7002&#39;</span><span class="p">,</span><span class="s1">&#39;7003&#39;</span><span class="p">,</span><span class="s1">&#39;4001&#39;</span><span class="p">,</span><span class="s1">&#39;4002&#39;</span><span class="p">,</span><span class="s1">&#39;4003&#39;</span><span class="p">]</span>
</span></span></code></pre></div><h3 id="起始url">起始url</h3>
<p>很显然歌手页有不同的分类，所有起始页不可能是单独的一个<code>url</code>，所以我们要重写<code>start_requests</code>。也就是构建所有的歌手分类页。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="k">for</span> <span class="n">initial</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">initials</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">			<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{url}</span><span class="s1">/discover/artist/cat?id=</span><span class="si">{id}</span><span class="s1">&amp;amp;initial=</span><span class="si">{initial}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_url</span><span class="p">,</span><span class="nb">id</span><span class="o">=</span><span class="nb">id</span><span class="p">,</span><span class="n">initial</span><span class="o">=</span><span class="n">initial</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">			<span class="k">yield</span> <span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_index</span><span class="p">)</span>
</span></span></code></pre></div><p>这一步实现起来逻辑还是很清晰的，循环每一个<code>id</code>，在循环每一个<code>initial</code>，将他们通过<code>.format</code>方法组成<code>url</code>。然后使用<code>yield</code>语法糖，将<code>url</code>回调给索引页解析函数。相信大家在前两篇理论的梳理下，对于这步操作没有什么问题。</p>
<p>那么我们在<code>parse_index()</code>函数中打印一下<code>Response</code>：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">parse_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</span></span></code></pre></div><p>控制台运行爬虫：<code>scrapy crawl music</code></p>
<p>由于<code>scrapy</code>不支持<code>lde</code>运行，所以如果我们非要想在比如<code>pycharm</code>中运行的话，我们需要编写一个运行程序：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 163music/entrypoint.py</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 注意这个文件在项目的根目录，也就是scrapy.cfg文件所在</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里的music就是爬虫的名字</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scrapy.cmdline</span> <span class="kn">import</span> <span class="n">execute</span>
</span></span><span class="line"><span class="cl"><span class="n">execute</span><span class="p">([</span><span class="s1">&#39;scrapy&#39;</span><span class="p">,</span> <span class="s1">&#39;crawl&#39;</span><span class="p">,</span> <span class="s1">&#39;music&#39;</span><span class="p">])</span>
</span></span></code></pre></div><p>现在我们在<code>pycharm</code>做运行这个文件就相当于运行爬虫了。</p>
<p>运行成功，但是我们好像并没有获得到我们想要的数据。这是怎么回事呢？
大家如果回忆使用<code>Requests</code>库请求的时候，我们在请求中有时候会添加一些请求头，那么<code>scrapy</code>中我们要在哪里添加呢。</p>
<p>答案很简单，就是在<code>settings.py</code>文件中。</p>
<h3 id="添加请求头设置">添加请求头设置</h3>
<p>我们需要在<code>settings</code>文件中先取消掉<code>DEFAULT_REQUEST_HEADERS</code>的注释，因为<code>scrapy</code>默认我们不需要请求头。我们在里面添加网易云的头部请求，就是我们开发者工具里的数据：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">DEFAULT_REQUEST_HEADERS</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;Accept&#39;</span><span class="p">:</span> <span class="s1">&#39;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;Accept-Encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate, sdch&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;Accept-Language&#39;</span><span class="p">:</span> <span class="s1">&#39;zh-CN,zh;q=0.8,en;q=0.6&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;Cache-Control&#39;</span><span class="p">:</span> <span class="s1">&#39;no-cache&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;Connection&#39;</span><span class="p">:</span> <span class="s1">&#39;keep-alive&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;Cookie&#39;</span><span class="p">:</span><span class="s1">&#39;_ntes_nuid=5e2135ea19041c08d61bddbb9009de63; _ntes_nnid=a387121ca9ed891dca82492f6c088c57,1483420952257; __utma=187553192.690483437.1489583101.1489583101.1489583101.1; __utmz=187553192.1489583101.1.1.utmcsr=google|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); __oc_uuid=ff821060-097f-11e7-8c2a-73421a9a1bc4; mail_psc_fingerprint=032ad52396a72877e07f21386dee35a2; NTES_CMT_USER_INFO=106964635%7C</span><span class="si">%E</span><span class="s1">6%9C</span><span class="si">%89%</span><span class="s1">E6</span><span class="si">%80%</span><span class="s1">81</span><span class="si">%E</span><span class="s1">5%BA%A6</span><span class="si">%E</span><span class="s1">7%BD</span><span class="si">%91%</span><span class="s1">E5</span><span class="si">%8F</span><span class="s1">%8B06o2qr%7Chttps%3A</span><span class="si">%2F%2F</span><span class="s1">simg.ws.126.net</span><span class="si">%2F</span><span class="s1">e</span><span class="si">%2F</span><span class="s1">img5.cache.netease.com</span><span class="si">%2F</span><span class="s1">tie</span><span class="si">%2F</span><span class="s1">images</span><span class="si">%2F</span><span class="s1">yun</span><span class="si">%2F</span><span class="s1">photo_default_62.png.39x39.100.jpg%7Cfalse%7CbTE1MTUyMzQ3Mjc3QDE2My5jb20%3D; usertrack=c+5+hlkgTIMgjwa+EDUGAg==; _ga=GA1.2.690483437.1489583101; Province=025; City=05278; NTES_PASSPORT=aXWcpL4bYTLQnXY4eO888VlwXt.v922HPG1pBkj.vkeDwsISwc4gjpib7gtylUsoCy.yIGuJPZg7Uq2lTWqIo3A5ddE7eIf5DP_mjdHrg7ky2KFIZHP60ge8g; P_INFO=m15152347277@163.com|1500267468|1|blog|11&amp;amp;10|jis&amp;amp;1499527300&amp;amp;mail163#jis&amp;amp;320800#10#0#0|151277&amp;amp;1|study&amp;amp;blog&amp;amp;photo|15152347277@163.com; UM_distinctid=15d4ee58fc9483-032aae6568b355-333f5902-100200-15d4ee58fca912; NTES_SESS=35juNvuVAClEtPfwjy5rP5GVXVpRFMmwg2ItfudhfLmyGTk4G2l_fIFHi_xsOJTWQrUJvW3JwsMFyepEs0SR6z1_QnKjbQFaesBY9ABy0TVFP_KIiXNgb89wCGe.3_hmKR90f2ybdvNPWqPX8_YesVlIQrWdw5Nfg6KF0EcoVXO3DgV09cJHAeiE_; S_INFO=1500623480|1|0&amp;amp;80##|m15152347277; ANTICSRF=dd45f2a4489d303de869d820a0dadf05; playerid=64643457; JSESSIONID-WYYY=oR0Q0Ce%2Bhldid</span><span class="si">%2F</span><span class="s1">Ftfsiobsg%5Cecyra1qnHBuFFPNBUW%2BbZ3%5C2uq5</span><span class="si">%2F</span><span class="s1">qz4VrhRll0%5CaVCfY</span><span class="si">%2F</span><span class="s1">g0%2BC47vS%5Cv6rsyuD76tlqWN%2BUryVxph9fZeCmVIDtu5so7vdcdp%2B92hI3A0R5Zm%2Besa5l3ND%5Cz59WOYTY</span><span class="si">%2F</span><span class="s1">CUjG%2B8gFSGVyzTpMquPQIxyIM%3A1500647790286; _iuqxldmzr_=32; MUSIC_U=f5333454d16d0f0ca5e59b3a82afaabcb107f5e73a4504bae87278f38158d65dbef309e3badc0bfac257abd5a88c5d62dc7e2cf554b1b3fc233a987fb3c42671e386323209b86ec1bf122d59fa1ed6a2; __remember_me=true; __csrf=5cd5b19efc6ea479e298487216162acf; __utma=94650624.776578804.1489210725.1500604214.1500644866.50; __utmb=94650624.28.10.1500644866; __utmc=94650624; __utmz=94650624.1499960824.48.42.utmcsr=yukunweb.com|utmccn=(referral)|utmcmd=referral|utmcct=/412.html&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;DNT&#39;</span><span class="p">:</span> <span class="s1">&#39;1&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;Host&#39;</span><span class="p">:</span> <span class="s1">&#39;music.163.com&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;Pragma&#39;</span><span class="p">:</span> <span class="s1">&#39;no-cache&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;Referer&#39;</span><span class="p">:</span> <span class="s1">&#39;http://music.163.com/&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;Upgrade-Insecure-Requests&#39;</span><span class="p">:</span> <span class="s1">&#39;1&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span><span class="s1">&#39;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>注意，网易云音乐的歌曲提取是要我们登录才可以获得数据的，我们直接加上登录后的<code>cookies</code>就可以了。</p>
<p>现在运行爬虫，如果运行成功，那么大家应该就能看到打印出来的数据了。这说明我们的程序是正确的。</p>
<h3 id="编写起始页解析函数">编写起始页解析函数</h3>
<p>这一步就要使用我们的选择器提取信息了，我们打开开发者工具，我们需要的就是歌手<code>a</code>标签中的<code>href</code>信息。对于还不会使用<code>xpath</code>和<code>css</code>选择器的可以使用<code>Chrome</code>开发者工具，右击该标签，如下图的操作：</p>
<p><img src="/image/post18/post18_2.jpg" alt="post18_2.jpg"></p>
<p>直接上解析起始页代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 获得所有歌手的url</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">parse_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">artists</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&#34;m-artist-box&#34;]/li/div/a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">artist</span> <span class="ow">in</span> <span class="n">artists</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="n">artist_url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_url</span> <span class="o">+</span> <span class="s1">&#39;/artist&#39;</span> <span class="o">+</span> <span class="s1">&#39;/album?&#39;</span> <span class="o">+</span> <span class="n">artist</span><span class="p">[</span><span class="mi">8</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">		<span class="k">yield</span> <span class="n">Request</span><span class="p">(</span><span class="n">artist_url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_artist</span><span class="p">)</span>
</span></span></code></pre></div><p>歌手专辑详情页<code>url</code>实例如：<code>https://music.163.com/#/artist/album?id=6452</code></p>
<p>我们解析得到<code>href</code>值后，在将他组合成完整的歌手专辑详情页<code>url</code>。然后回调给下一个解析函数。</p>
<h3 id="提取所有专辑url">提取所有专辑url</h3>
<p>这一步和上一步一样，由于这一步也没什么难点，不过多赘述。上代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 获得所有歌手专辑的url</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">parse_artist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">albums</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&#34;m-song-module&#34;]/li/div/a[@class=&#34;msk&#34;]/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">album</span> <span class="ow">in</span> <span class="n">albums</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="n">album_url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_url</span> <span class="o">+</span> <span class="n">album</span>
</span></span><span class="line"><span class="cl">		<span class="k">yield</span> <span class="n">Request</span><span class="p">(</span><span class="n">album_url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_album</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="提取所有歌曲">提取所有歌曲</h3>
<p>这一步就有一点不同了，因为如果我们提取了音乐<code>url</code>，那么我们需要的音乐<code>id</code>就在<code>url</code>中。如果我们直接将<code>URL</code>回调给解析音乐页的函数后，我们在后面是获取不到这个<code>id</code>的。大家可以自己观察页面，确定这一步。</p>
<p>所以我们不仅要把<code>url</code>回调给下一个解析函数，还要把音乐<code>id</code>传给下一个函数。那么大家应该会有疑问，为什么不把<code>id</code>直接保存到<code>item</code>呢。</p>
<p>这是因为我们需要的数据结构会是这样：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">{&#39;id&#39;:123456,&#39;music&#39;:&#39;晴天&#39;,&#39;artist&#39;:&#39;周杰伦&#39;,&#39;album&#39;:&#39;叶美惠&#39;,&#39;comments&#39;:[{&#39;comment_author&#39;:&#39;小明&#39;,&#39;comment_content&#39;:&#39;我爱你&#39;,&#39;comment_like&#39;:&#39;123456&#39;},{...},{}...]}
</span></span></code></pre></div><p>如果我们现在保存了音乐<code>id</code>，那么后面的信息能否对应我们也不确定。那么怎样才能将数据传给下一个函数呢？</p>
<p><code>scrapy</code>给我提供了<code>meta</code>参数用来保存我们的数据传给函数，我们来看代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 获得所有专辑音乐的url</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">parse_album</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">musics</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//ul[@class=&#34;f-hide&#34;]/li/a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">music</span> <span class="ow">in</span> <span class="n">musics</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="n">music_id</span> <span class="o">=</span> <span class="n">music</span><span class="p">[</span><span class="mi">9</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">		<span class="n">music_url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_url</span> <span class="o">+</span> <span class="n">music</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="k">yield</span> <span class="n">Request</span><span class="p">(</span><span class="n">music_url</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">music_id</span><span class="p">},</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_music</span><span class="p">)</span>
</span></span></code></pre></div><p>像这样我们把组合的<code>URL</code>传给解析函数，也将音乐<code>id</code>传给下一个函数。</p>
<h3 id="提取音乐信息分析评论ajax">提取音乐信息，分析评论Ajax</h3>
<p>对于提取页面的音乐信息，使用选择器提取就可以了，难的是评论区并不在我们获取的源码中。如果大家有疑惑，可以打印一些音乐详情页的源码。那么评论的信息究竟在哪呢，这是相信大家心里都开始怀疑这是不是<code>Ajax</code>加载的呢。</p>
<p>为了验证这个疑惑，我们点击评论区的翻页，可以看到到了第二页浏览器的<code>url</code>并没有变化。这个时候基本上可以知道这是<code>ajax</code>加载的页面了。</p>
<p>我们之前有一篇说过<code>Ajax</code>请求的处理方法，我们这里不多余赘述。打开<code>Chrome</code>开发者工具，点开<code>Network</code>标签的<code>XHR</code>刷新页面，这时候会有几个请求出来。我们一个一个点开看他们的响应内容，发现<code>R_SO_4_186016?csrf_token=</code>请求中包含了评论的信息。数一下热评数在对比页面中的热评信息，完全一致。我们看下面的图片：</p>
<p><img src="/image/post18/post18_3.jpg" alt="post18_3.jpg"></p>
<p><img src="/image/post18/post18_4.jpg" alt="post18_4.jpg"></p>
<p>通过上面一张图片，红框里框出的<code>Form Data</code>数据，没错，这是一个<code>Post</code>请求信息。接着我们就要将他们构造成字典通过<code>post</code>请求。我们在看图中的<code>referer</code>的url，没错url后面的id就是歌曲的id。上一个函数我们将歌曲id也传过来是不是很方便这一步的处理呢。</p>
<p>我们需要在之前的请求头中加入每个音乐请求的<code>referer</code>参数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">DEFAULT_REQUEST_HEADERS[&#39;Referer&#39;] = self.base_url + &#39;/playlist?id=&#39; + str(music_id)
</span></span></code></pre></div><p>将<code>Form Data</code>构造字典大家都没问题，构造<code>Ajax</code>请求<code>url</code>就是<code>R_SO_4_</code>后面接上音乐的<code>id</code>。也没问题，那么在<code>scrapy</code>中怎么使用<code>Post</code>请求呢。</p>
<p>答案就是scrapy的<code>FormRequest</code>方法，我们需要导入他，然后用法和<code>Request</code>一样，我们还需要将这个函数提取的所有音乐信息传给下一个提取热评的函数，然后将所有数据一起传给<code>item</code>。</p>
<p>代码如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 获得音乐信息</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">parse_music</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">music_id</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">music</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//div[@class=&#34;tit&#34;]/em[@class=&#34;f-ff2&#34;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="n">artist</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//div[@class=&#34;cnt&#34;]/p[1]/span/a/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="n">album</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//div[@class=&#34;cnt&#34;]/p[2]/a/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="s1">&#39;csrf_token&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="s1">&#39;Ak2s0LoP1GRJYqE3XxJUZVYK9uPEXSTttmAS+8uVLnYRoUt/Xgqdrt/13nr6OYhi75QSTlQ9FcZaWElIwE+oz9qXAu87t2DHj6Auu+2yBJDr+arG+irBbjIvKJGfjgBac+kSm2ePwf4rfuHSKVgQu1cYMdqFVnB+ojBsWopHcexbvLylDIMPulPljAWK6MR8&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="s1">&#39;encSecKey&#39;</span><span class="p">:</span> <span class="s1">&#39;8c85d1b6f53bfebaf5258d171f3526c06980cbcaf490d759eac82145ee27198297c152dd95e7ea0f08cfb7281588cdab305946e01b9d84f0b49700f9c2eb6eeced8624b16ce378bccd24341b1b5ad3d84ebd707dbbd18a4f01c2a007cd47de32f28ca395c9715afa134ed9ee321caa7f28ec82b94307d75144f6b5b134a9ce1a&#39;</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="n">DEFAULT_REQUEST_HEADERS</span><span class="p">[</span><span class="s1">&#39;Referer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_url</span> <span class="o">+</span> <span class="s1">&#39;/playlist?id=&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">music_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">music_comment</span> <span class="o">=</span> <span class="s1">&#39;http://music.163.com/weapi/v1/resource/comments/R_SO_4_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">music_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">yield</span> <span class="n">FormRequest</span><span class="p">(</span><span class="n">music_comment</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span><span class="n">music_id</span><span class="p">,</span><span class="s1">&#39;music&#39;</span><span class="p">:</span><span class="n">music</span><span class="p">,</span><span class="s1">&#39;artist&#39;</span><span class="p">:</span><span class="n">artist</span><span class="p">,</span><span class="s1">&#39;album&#39;</span><span class="p">:</span><span class="n">album</span><span class="p">},</span> \
</span></span><span class="line"><span class="cl">				  <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_comment</span><span class="p">,</span> <span class="n">formdata</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="提取热评信息传给item">提取热评信息传给item</h3>
<p>这是爬虫部分的最后一步了，这一步从<code>Ajax</code>请求的<code>json</code>数据了提取信息，相信大家都会，就不去多说。我们提取到所有的数据后，就是传给<code>item</code>了。</p>
<p><code>item</code>的操作和字典是一样的，我们就像保存字典数据一样保存他们就可以了。但是那么多数据写字典那样一步一步的是不是很蠢呢。那有没有方便一点的方法了。这个时候内置的<code>eval</code>方法派上用场，这里不做方法的讲解，用起来很简单，他会动态的获取我们字典的每一个键，然后帮我们保存。我们看代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 获得所有音乐的热评数据</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">json</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">parse_comment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="nb">id</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">music</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s1">&#39;music&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">artist</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s1">&#39;artist&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">album</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s1">&#39;album&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	<span class="n">result</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">comments</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="s1">&#39;hotComments&#39;</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">		<span class="k">for</span> <span class="n">comment</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;hotComments&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">			<span class="n">hotcomment_author</span> <span class="o">=</span> <span class="n">comment</span><span class="p">[</span><span class="s1">&#39;user&#39;</span><span class="p">][</span><span class="s1">&#39;nickname&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">			<span class="n">hotcomment</span> <span class="o">=</span> <span class="n">comment</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">			<span class="n">hotcomment_like</span> <span class="o">=</span> <span class="n">comment</span><span class="p">[</span><span class="s1">&#39;likedCount&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">			<span class="c1"># 这里我们将评论的作者头像也保存，如果大家喜欢这个项目，我后面可以做个web端的展现</span>
</span></span><span class="line"><span class="cl">			<span class="n">hotcomment_avatar</span> <span class="o">=</span> <span class="n">comment</span><span class="p">[</span><span class="s1">&#39;user&#39;</span><span class="p">][</span><span class="s1">&#39;avatarUrl&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">			<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">				<span class="s1">&#39;nickname&#39;</span><span class="p">:</span> <span class="n">hotcomment_author</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">				<span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">hotcomment</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">				<span class="s1">&#39;likedcount&#39;</span><span class="p">:</span> <span class="n">hotcomment_like</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">				<span class="s1">&#39;avatarurl&#39;</span><span class="p">:</span> <span class="n">hotcomment_avatar</span>
</span></span><span class="line"><span class="cl">    		<span class="p">}</span>
</span></span><span class="line"><span class="cl">			<span class="n">comments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">item</span> <span class="o">=</span> <span class="n">MusicItem</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="c1"># 由于eval方法不稳定，具体的可以自己搜索，我们过滤一下错误</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">fields</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">			<span class="n">item</span><span class="p">[</span><span class="n">field</span><span class="p">]</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">field</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="k">except</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">			<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Field is not defined&#39;</span><span class="p">,</span> <span class="n">field</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="k">yield</span> <span class="n">item</span>
</span></span></code></pre></div><p>最后我们将数据传给<code>Item</code>。</p>
<h3 id="pipeline中处理数据">Pipeline中处理数据</h3>
<p>在<code>Pipeline</code>中处理数据，其实我们这里没什么好对数据做什么改动的，这里我们要对数据做数据库的保存。</p>
<p>我们需要创建一个<code>mongodb</code>类。然后在<code>settings</code>中将<code>ITEM_PIPELINES</code>的键改为我们创建的<code>mongdb</code>类，由于我们不需要对数据进行改动，所以直接覆盖就好了。为了方便管理和整体架构的清晰，我们也需要在<code>settings</code>中设置我们的数据库信息。具体代码如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">   <span class="s1">&#39;music163.pipelines.MongoPipeline&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 添加数据库信息</span>
</span></span><span class="line"><span class="cl"><span class="n">MONGO_URI</span> <span class="o">=</span> <span class="s1">&#39;localhost&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">MONGO_DB</span> <span class="o">=</span> <span class="s1">&#39;music163&#39;</span>
</span></span></code></pre></div><p>接下来就是写我们的<code>Mongodb</code>类了。首先我们需要给这个类传入两个参数，也就是我们前面在<code>settings</code>文件定义的数据库<code>uri</code>和数据库名，我们对它们进行一个赋值：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MongoPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mongo_uri</span><span class="p">,</span> <span class="n">mongo_db</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="bp">self</span><span class="o">.</span><span class="n">mongo_uri</span> <span class="o">=</span> <span class="n">mongo_uri</span>
</span></span><span class="line"><span class="cl">		<span class="bp">self</span><span class="o">.</span><span class="n">mongo_db</span> <span class="o">=</span> <span class="n">mongo_db</span>
</span></span></code></pre></div><p>接下来我们定义一个<code>from_crawler</code>类方法，这个方法就相当于将这个类的两个参数通过<code>crawler</code>对象从 settings 中拿到这两个参数（数据库uri和名称）。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MongoPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mongo_uri</span><span class="p">,</span> <span class="n">mongo_db</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="bp">self</span><span class="o">.</span><span class="n">mongo_uri</span> <span class="o">=</span> <span class="n">mongo_uri</span>
</span></span><span class="line"><span class="cl">		<span class="bp">self</span><span class="o">.</span><span class="n">mongo_db</span> <span class="o">=</span> <span class="n">mongo_db</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="nd">@classmethod</span>
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="nf">from_crawler</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">crawler</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">			<span class="n">mongo_uri</span><span class="o">=</span><span class="n">crawler</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;MONGO_URI&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">			<span class="n">mongo_db</span><span class="o">=</span><span class="n">crawler</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;MONGO_DB&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="nf">open_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">pymongo</span><span class="o">.</span><span class="n">MongoClient</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mongo_uri</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="bp">self</span><span class="o">.</span><span class="n">db</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">mongo_db</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="nf">close_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span></code></pre></div><p>这里的<code>@classmethod</code>装饰器是<code>python</code>中比较常用的一个方法，具体操作大家可以参阅相关资料了解他。</p>
<p>后面的<code>open_spider()</code>和<code>close_spider()</code>方法其实是重定义的一个类方法，意思就是我们在启动爬虫的开始，调用<code>open_spider()</code>方法，在关闭爬虫是调用<code>close_spider()</code>方法。我们给他们添加启动数据库和关闭数据库的操作。</p>
<p>后面是最重要的方法，<code>process_item()</code>方法就是用来对<code>item</code>进行操作的。我们这里主要就是对数据库进行一个插入操作。</p>
<p>首先我们需要在<code>items.py</code>文件中加入一个 <code>table_name = 'music'</code>的属性，也就是相当于一个数据库表名。这样做方便我们将这个属性传到<code>process_item()</code>方法，我们需要调用数据库的<code>update</code>方法：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">db</span><span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">table_name</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">item</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">)},</span> <span class="p">{</span><span class="s1">&#39;$set&#39;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">item</span><span class="p">)},</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="n">item</span>
</span></span></code></pre></div><p>这个方法有三个参数，第一个参数传入数据库查询的字段，我们使用音乐的<code>id</code>来进行查询。</p>
<p>第二个参数就是我们的<code>item</code>数据，我们将他转化为字典形式。</p>
<p>第三个参数至关重要，我们传入<code>True</code>。意思是如果我们查询到相同的数据，我们就做更新操作，如果没有查询到相同的数据就做插入操作。这就相当于我们己做了插入数据库同时有做了去重的操作。</p>
<h2 id="最后">最后</h2>
<p>好了，这样我们的爬虫就完成了，整理完代码运行起来吧。</p>
<h2 id="项目地址">项目地址</h2>
<p><a href="https://github.com/Blackyukun/163Music">github</a></p>
<p>谢谢阅读</p>
</div>
                    <div class="post_footer">
                        
                        <div class="meta">
                            <div class="info">
                                <span class="field tags">
                                    <i class="ri-stack-line"></i>
                                    
                                    <a href="https://yokonsan.com/tags/python/">Python</a>
                                    
                                    <a href="https://yokonsan.com/tags/%E7%88%AC%E8%99%AB/">爬虫</a>
                                    
                                </span>
                            </div>
                        </div>
                        
                    </div>
                </div>
                
                
                <div class="doc_comments"></div>
                
            </div>
        </div>
    </div>
    <a id="back_to_top" href="#" class="back_to_top"><i class="ri-arrow-up-s-line"></i></a>
    <footer class="footer">
    <div class="powered_by">
        <a href="https://github.com/varkai/hugo-theme-zozo">Designed by zozo | </a>
        <a href="http://www.gohugo.io/">Proudly published with Hugo | </a>
        <a href="https://beian.miit.gov.cn/">苏ICP备17028833号-3</a>
    </div>

    <div class="footer_slogan">
        <span>君子终日乾乾，夕惕若厉，无咎。</span>
        
    </div>

    <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?7256012830beb794d5f4468b53b5891e";
          var s = document.getElementsByTagName("script")[0]; 
          s.parentNode.insertBefore(hm, s);
        })();
    </script>
        
</footer>
    <script src="https://yokonsan.com/js/jquery-3.5.1.min.js"></script>
<link href="https://yokonsan.com/css/fancybox.min.css" rel="stylesheet">
<script src="https://yokonsan.com/js/fancybox.min.js"></script>
<script src="https://yokonsan.com/js/zozo.js"></script>


<script type="text/javascript" async
    src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\[\[', '\]\]']],
                processEscapes: true,
                processEnvironments: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
                TeX: {
                    equationNumbers: { autoNumber: "AMS" },
                    extensions: ["AMSmath.js", "AMSsymbols.js"]
                }
            }
        });

        MathJax.Hub.Queue(function () {
            
            
            
            var all = MathJax.Hub.getAllJax(), i;
            for (i = 0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
            }
        });
    </script>

<style>
    code.has-jax {
        font: inherit;
        font-size: 100%;
        background: inherit;
        border: inherit;
        color: #515151;
    }
</style>



</body>

</html>