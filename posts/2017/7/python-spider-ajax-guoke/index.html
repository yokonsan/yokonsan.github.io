<!DOCTYPE html>
<html lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="yokonsan" />
	
	
	
	<title>Python爬虫(8):分析Ajax请求爬取果壳网 ｜ 乾之 三爻</title>
	
    
    
    <meta name="description" content="本篇文章我们来研究一下怎么分析网页的Ajax请求。 我们在平时爬取网页的时候，可能都遇到过有些网页直接请求得到的 HTML 代码里面，并没有我们需要的数据，也就是我们在浏览器中看到的内容。 这就是因为这些信息是通过" />
    

    
    
    <meta name="keywords" content="技术, 生活, 分享" />
    

	
    
    <link rel="shortcut icon" href="https://yokonsan.com/images/favicon.ico" />

    <link rel="stylesheet" type="text/css" media="screen" href="https://yokonsan.com/css/normalize.css" />
    <link rel="stylesheet" type="text/css" media="screen" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" />
    <link rel="stylesheet" type="text/css" media="screen" href="https://yokonsan.com/css/zozo.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" />
    <link rel="stylesheet" type="text/css" media="screen" href="https://yokonsan.com/css/highlight.css" />

    
    
</head>

<body>
    <div class="main animate__animated animate__fadeInDown">
        <div class="nav_container animated fadeInDown">
    <div class="site_nav" id="site_nav">
        <ul>
            
            <li>
                <a href="/">Home</a>
            </li>
            
            <li>
                <a href="/posts/">Archive</a>
            </li>
            
            <li>
                <a href="/tags/">Tags</a>
            </li>
            
            <li>
                <a href="/about/">About</a>
            </li>
            
            <li>
                <a href="/links/">Links</a>
            </li>
            
        </ul>
    </div>
    <div class="menu_icon">
        <a id="menu_icon"><i class="ri-menu-line"></i></a>
    </div>
</div>
        <div class="header animated fadeInDown">
    <div class="site_title_container">
        <div class="site_title">
            <h1>
                <a href="https://yokonsan.com/">
                    <span>乾之 三爻</span>
                </a>
            </h1>
        </div>
        <div class="description">
            <p class="sub_title">yokon&#39;s blog</p>
            <div class="my_socials">
                
                
                <a href="https://github.com/yokonsan" title="github" target="_blank"><i class="ri-github-fill"></i></a>
                
                
                
                <a href="https://ai.yokonsan.com" title="instagram" target="_blank"><i class="ri-instagram-fill"></i></a>
                
                
                <a href="https://yokonsan.com/index.xml" type="application/rss+xml" title="rss" target="_blank"><i
                        class="ri-rss-fill"></i></a>
            </div>
        </div>
    </div>
</div>
        <div class="content">
            <div class="post_page">
                <div class="post animate__animated animate__fadeInDown">
                    <div class="post_title post_detail_title">
                        <h2><a href='/posts/2017/7/python-spider-ajax-guoke/'>Python爬虫(8):分析Ajax请求爬取果壳网</a></h2>
                        <span class="date">2017.07.17</span>
                    </div>
                    <div class="post_content markdown"><p>本篇文章我们来研究一下怎么分析网页的<code>Ajax</code>请求。</p>
<p>我们在平时爬取网页的时候，可能都遇到过有些网页直接请求得到的 HTML 代码里面，并没有我们需要的数据，也就是我们在浏览器中看到的内容。</p>
<p>这就是因为这些信息是通过<code>Ajax</code>加载的，并且通过<code>js</code>渲染生成的。这个时候我们就需要分析这个网页的请求了。</p>
<h2 id="什么是ajax">什么是Ajax</h2>
<blockquote>
<p>AJAX即“Asynchronous Javascript And XML”（异步JavaScript和XML），是指一种创建交互式网页应用的网页开发技术。</p>
</blockquote>
<blockquote>
<p>AJAX = 异步 JavaScript和XML（标准通用标记语言的子集）。</p>
</blockquote>
<blockquote>
<p>AJAX 是一种用于创建快速动态网页的技术。</p>
</blockquote>
<blockquote>
<p>AJAX 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。</p>
</blockquote>
<p>简单的说就是网页加载，浏览器地址栏的网址并没有变，是<code>javascript</code>异步加载的网页，应该是<code>ajax</code>。<code>AJAX</code>一般是通过<code> XMLHttpRequest</code> 对象接口发送请求的，<code>XMLHttpRequest</code> 一般被缩写为 <code>XHR</code>。</p>
<h2 id="分析果壳网站点">分析果壳网站点</h2>
<p>我们目标网站就以果壳网来进行分析。<a href="http://www.guokr.com/scientific/">地址</a></p>
<p>我们可以看到这个网页并没有翻页按钮，而当我们一直往下拉请求，网页会自动的给我们加载出更多内容。但是，当我们观察网页<code>url</code>时，发现它并没有随着网页的加载请求而变化。而当我们直接请求这个<code>url</code>时，显然我们只能获得到第一页的<code>html</code>内容。</p>
<p><img src="/image/post13/post13_1.jpg" alt="post13_1.jpg"></p>
<h3 id="那我们要怎么获得所有页的数据呢">那我们要怎么获得所有页的数据呢？</h3>
<p>我们在<code>Chrome</code>中打开开发者工具<code>(F12)</code>。我们点击<code>Network</code>，点击<code>XHR</code>标签。然后我们刷新网页，往下拉请求。这个时候我们就可以看到<code>XHR</code>标签，在网页每一次加载的时候就会跳出一个请求。</p>
<p>我们点击第一个请求，可以看到他的参数：</p>
<blockquote>
<p>retrieve_type:by_subject</p>
</blockquote>
<blockquote>
<p>limit:20</p>
</blockquote>
<blockquote>
<p>offset:18</p>
</blockquote>
<blockquote>
<p>-:1500265766286</p>
</blockquote>
<p>在点击第二个请求，参数如下：</p>
<blockquote>
<p>retrieve_type:by_subject</p>
</blockquote>
<blockquote>
<p>limit:20</p>
</blockquote>
<blockquote>
<p>offset:38</p>
</blockquote>
<blockquote>
<p>-:1500265766287</p>
</blockquote>
<p><code>limit</code>参数是网页每一页限制加载的文章数，<code>offset</code>就是页数了。接着往下看，我们会发现每一个请求的<code>offset</code>参数都会加 20。</p>
<p>我们接着看每一个请求的响应内容，这是一个就是格式的数据。我们点开<code>result</code>键，可以看到一个 20 篇文章的数据信息。这样我们就成功找到我们需要的信息位置了，我们可以在请求头中看到存放<code>json</code>数据的<code>url</code>地址。<code>http://www.guokr.com/apis/minisite/article.json?retrieve_type=by_subject&amp;amp;limit=20&amp;amp;offset=18</code></p>
<p><img src="/image/post13/post13_2.jpg" alt="post13_2.jpg"></p>
<h2 id="爬取流程">爬取流程</h2>
<ul>
<li>分析Ajax请求获得每一页的文章url信息；</li>
<li>解析每一篇文章，获得需要数据；</li>
<li>将获得的数据保存数据库；</li>
<li>开启多进程，大量抓取。</li>
</ul>
<h2 id="开始">开始</h2>
<p>我们的工具仍然使用<code>requests</code>请求，<code>BeautifulSoup</code>解析。</p>
<p>首先我们要通过分析<code>Ajax</code>请求，获得所有页的信息，通过对上面对网页的分析，可以得到<code>Ajax</code>加载的<code>json</code>数据的<code>URL</code>地址为：<code>http://www.guokr.com/apis/minisite/article.json?retrieve_type=by_subject&amp;amp;limit=20&amp;amp;offset=18</code></p>
<p>我们需要构造这个 URL。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 导入可能要用到的模块</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">requests</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urlencode</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">requests.exceptions</span> <span class="kn">import</span> <span class="ne">ConnectionError</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 获得索引页的信息</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_index</span><span class="p">(</span><span class="n">offset</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;http://www.guokr.com/apis/minisite/article.json?&#39;</span>
</span></span><span class="line"><span class="cl">	<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="s1">&#39;retrieve_type&#39;</span><span class="p">:</span> <span class="s2">&#34;by_subject&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="s1">&#39;limit&#39;</span><span class="p">:</span> <span class="s2">&#34;20&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="s1">&#39;offset&#39;</span><span class="p">:</span> <span class="n">offset</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="n">params</span> <span class="o">=</span> <span class="n">urlencode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">url</span> <span class="o">=</span> <span class="n">base_url</span> <span class="o">+</span> <span class="n">params</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="n">resp</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">			<span class="k">return</span> <span class="n">resp</span><span class="o">.</span><span class="n">text</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">	<span class="k">except</span> <span class="ne">ConnectionError</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Error.&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="kc">None</span>
</span></span></code></pre></div><p>我们把上面分析页面得到的请求参数构造成一个字典<code>data</code>，然后我们可以手动的构造这个<code>url</code>，但是<code>urllib</code>库已经给我们提供了一个编码方法，我们直接使用，就可以构造出完整的<code>url</code>了。然后是标准的<code>requests</code>请求页面内容。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">json</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 解析json，获得文章url</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">parse_json</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="n">result</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="n">result</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">			<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;result&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">				<span class="c1"># print(i.get(&#39;url&#39;))</span>
</span></span><span class="line"><span class="cl">				<span class="k">yield</span> <span class="n">i</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;url&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="k">except</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="k">pass</span>
</span></span></code></pre></div><p>我们使用<code>josn.loads</code>方法解析<code>json</code>，将其转化成一个<code>json</code>对象。然后直接通过字典的操作，获得文章的<code>url</code>地址。这里使用<code>yield</code>，每次请求返回一个<code>url</code>，降低内存的消耗。由于我在后面抓取的时候出跳出一个<code>json</code>解析的错误，这里直接过滤就好。</p>
<p>这里我们可以试着打印看看，是不是成功运行。</p>
<p>既然获得了文章的<code>url</code>，那么对于获得文章的数据就显得很简单了。这里不在进行详细的叙述。我们的目标是获得文章的标题，作者和内容。
由于有的文章里面包含一些图片，我们直接过滤掉文章内容里的图片就好了。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 解析文章页</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">parse_page</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;lxml&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">content</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&#34;content&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">title</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;h1&#39;</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s2">&#34;articleTitle&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">		<span class="n">author</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&#34;content-th-info&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">		<span class="n">article_content</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&#34;document&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">all_p</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">article_content</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;img&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">i</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">		<span class="n">article</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">all_p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="c1"># print(title,&#39;\n&#39;,author,&#39;\n&#39;,article)</span>
</span></span><span class="line"><span class="cl">		<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">			<span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="n">author</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">			<span class="s1">&#39;article&#39;</span><span class="p">:</span> <span class="n">article</span>
</span></span><span class="line"><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="n">data</span>
</span></span><span class="line"><span class="cl">	<span class="k">except</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="k">pass</span>
</span></span></code></pre></div><p>这里在进行多进程抓取的时候，<code>BeautifulSoup</code>也会出现一个错误，依然直接过滤。我们把得到的数据保存为字典的形式，方便保存数据库。</p>
<p>接下来就是保存数据库的操作了，这里我们使用<code>Mongodb</code>进行数据的存储。具体的方法在上一篇文章里有说过。不在对他进行详细叙述。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pymongo</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">config</span> <span class="kn">import</span> <span class="o">*</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">pymongo</span><span class="o">.</span><span class="n">MongoClient</span><span class="p">(</span><span class="n">MONGO_URL</span><span class="p">,</span> <span class="mi">27017</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">db</span> <span class="o">=</span> <span class="n">client</span><span class="p">[</span><span class="n">MONGO_DB</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">save_database</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="n">db</span><span class="p">[</span><span class="n">MONGO_TABLE</span><span class="p">]</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Save to Database successful&#39;</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="kc">False</span>
</span></span></code></pre></div><p>我们把数据库的名字，和表名保存到<code>config</code>配置文件中，在把配置信息导入文件，这样会方便代码的管理。</p>
<p>最后呢，由于果壳网数据还是比较多的，如果想要大量的抓取，我们可以使用多进程。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Pool</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 定义一个主函数</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">offset</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">text</span> <span class="o">=</span> <span class="n">get_index</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">all_url</span> <span class="o">=</span> <span class="n">parse_json</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">all_url</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="n">resp</span> <span class="o">=</span> <span class="n">get_page</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">data</span> <span class="o">=</span> <span class="n">parse_page</span><span class="p">(</span><span class="n">resp</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="n">data</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">			<span class="n">save_database</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">	<span class="n">pool</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="n">offsets</span> <span class="o">=</span> <span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="mi">20</span><span class="o">+</span><span class="mi">18</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">500</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">	<span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">main</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="n">pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</span></span></code></pre></div><p>函数的参数<code>offset</code>就是页数了。经过我的观察，果壳网最后一页页码是 12758，有 637 页。这里我们就抓取 500 页。进程池的<code>map</code>方法和<code>Python</code>内置的<code>map</code>方法使用类似。</p>
<p><img src="/image/post13/post13_3.jpg" alt="post13_3.jpg"></p>
<p>好了，对于一些使用<code>Ajax</code>加载的网页，我们就可以这么抓取了。</p>
<h2 id="项目地址">项目地址</h2>
<p><a href="https://github.com/Blackyukun/GuoKe">here</a></p>
<p>如果觉得有帮助，不妨<strong>star</strong>。</p>
<p>谢谢阅读</p>
</div>
                    <div class="post_footer">
                        
                        <div class="meta">
                            <div class="info">
                                <span class="field tags">
                                    <i class="ri-stack-line"></i>
                                    
                                    <a href="https://yokonsan.com/tags/python/">Python</a>
                                    
                                    <a href="https://yokonsan.com/tags/%E7%88%AC%E8%99%AB/">爬虫</a>
                                    
                                </span>
                            </div>
                        </div>
                        
                    </div>
                </div>
                
                
                <div class="doc_comments"></div>
                
            </div>
        </div>
    </div>
    <a id="back_to_top" href="#" class="back_to_top"><i class="ri-arrow-up-s-line"></i></a>
    <footer class="footer">
    <div class="powered_by">
        <a href="https://github.com/varkai/hugo-theme-zozo">Designed by zozo | </a>
        <a href="http://www.gohugo.io/">Proudly published with Hugo | </a>
        <a href="https://beian.miit.gov.cn/">苏ICP备17028833号-3</a>
    </div>

    <div class="footer_slogan">
        <span>君子终日乾乾，夕惕若厉，无咎。</span>
        
    </div>

    <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?7256012830beb794d5f4468b53b5891e";
          var s = document.getElementsByTagName("script")[0]; 
          s.parentNode.insertBefore(hm, s);
        })();
    </script>
        
</footer>
    <script src="https://yokonsan.com/js/jquery-3.5.1.min.js"></script>
<link href="https://yokonsan.com/css/fancybox.min.css" rel="stylesheet">
<script src="https://yokonsan.com/js/fancybox.min.js"></script>
<script src="https://yokonsan.com/js/zozo.js"></script>


<script type="text/javascript" async
    src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\[\[', '\]\]']],
                processEscapes: true,
                processEnvironments: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
                TeX: {
                    equationNumbers: { autoNumber: "AMS" },
                    extensions: ["AMSmath.js", "AMSsymbols.js"]
                }
            }
        });

        MathJax.Hub.Queue(function () {
            
            
            
            var all = MathJax.Hub.getAllJax(), i;
            for (i = 0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
            }
        });
    </script>

<style>
    code.has-jax {
        font: inherit;
        font-size: 100%;
        background: inherit;
        border: inherit;
        color: #515151;
    }
</style>



</body>

</html>